{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1b2ab282",
      "metadata": {
        "id": "1b2ab282"
      },
      "source": [
        "# Лабораторная работа 1\n",
        "\n",
        "Цель: освоить основные инструменты для предварительной обработки и первичного анализа текстовых данных\n",
        "\n",
        "### План\n",
        "\n",
        "*   Exploratory Data Analysis (EDA) - Первичный/разведочный анализ и очистка данных\n",
        "*   Предварительная обработка текстовых данных\n",
        "*   Формирование векторов/массивов признаков (feature vectors) для обучения модели\n",
        "*   Кодирование категориальных целевых перемменных (Labelling)\n",
        "*   Построение простейшей нейронной сети для классификации в Tensorflow.Keras\n",
        "*   Оценка качества обучения  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pymorphy3"
      ],
      "metadata": {
        "id": "T9XbGc1FOf2P"
      },
      "id": "T9XbGc1FOf2P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a22db5b3",
      "metadata": {
        "id": "a22db5b3"
      },
      "outputs": [],
      "source": [
        "# Импорт необходимых библиотек\n",
        "# Успешное выполнение этой ячейки кода подтверждает правильную настройку среды разработки\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import pymorphy3\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout1D, BatchNormalization, Embedding, Flatten, Activation\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20b0d2e1",
      "metadata": {
        "id": "20b0d2e1"
      },
      "source": [
        "# Exploratory Data Analysis (EDA) - Первичный/разведочный анализ и очистка данных\n",
        "\n",
        "Вы снова будете работать с тем же датасетом из обращений граждан.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee0f5520",
      "metadata": {
        "id": "ee0f5520"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Lesson_1_user_requests.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Нас интересуют только значения \"process_texts\" - тексты самих обращений, \"sphera\" - тема, к которой относится письмо, и \"categoriya\" - категория обращений\n",
        "df_text = df.copy(deep=True)\n",
        "df_text = df_text[['process_texts','sphera', 'categoriya']]\n",
        "df_text.head(10)"
      ],
      "metadata": {
        "id": "i_8hVzhkR6Bf"
      },
      "id": "i_8hVzhkR6Bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d8cec12-9dd2-402a-9678-60f9536a5831",
      "metadata": {
        "id": "0d8cec12-9dd2-402a-9678-60f9536a5831"
      },
      "outputs": [],
      "source": [
        "# Ещё один удобный способ посмотреть на количество ненулевых и уникальных значений в таблице по каждой переменной (как и другие статистики по численным ппеременным) - функция describe()\n",
        "df_text.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1 (Удаление пустых строк)\n",
        "Найдите и удалите из таблицы все строки с пропущенными значениями текстов обращений и вашей целевой переменной (в зависимости от варианта sphera или categoriya)"
      ],
      "metadata": {
        "id": "LSgRcSVfUIps"
      },
      "id": "LSgRcSVfUIps"
    },
    {
      "cell_type": "code",
      "source": [
        "#### ВСТАВЬТЕ КОД СЮДА\n",
        "...\n",
        "####\n",
        "\n",
        "print(\"Всего строк в таблице без пропущенных значений: \", df_text.shape[0])"
      ],
      "metadata": {
        "id": "5g6Reec2UGLa"
      },
      "id": "5g6Reec2UGLa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2 (Удаление повторяющихся обращений)\n",
        "Найдите и удалите из таблицы все повторяющиеся обращения (полные дубликаты)."
      ],
      "metadata": {
        "id": "ZVLPPXPHWHZn"
      },
      "id": "ZVLPPXPHWHZn"
    },
    {
      "cell_type": "code",
      "source": [
        "#### ВСТАВЬТЕ КОД СЮДА\n",
        "...\n",
        "####\n",
        "\n",
        "print(f'Таблца без повторяющихся обращений содержит {df_text.shape[0]} строк.')"
      ],
      "metadata": {
        "id": "G7BNEsqcWk4A"
      },
      "id": "G7BNEsqcWk4A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь посмотрим на распределение целевых переменных по классам"
      ],
      "metadata": {
        "id": "wfzmRNb0VrIY"
      },
      "id": "wfzmRNb0VrIY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "061d1de5-ab74-4902-b5e1-263f0468ab1f",
      "metadata": {
        "id": "061d1de5-ab74-4902-b5e1-263f0468ab1f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.countplot(y='sphera', data=df_text)\n",
        "plt.title('Распределение по сферам')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5121f36-7cbd-46ec-acdb-c16f7267ebf8",
      "metadata": {
        "id": "f5121f36-7cbd-46ec-acdb-c16f7267ebf8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.countplot(y='categoriya', data=df_text)\n",
        "plt.title('Распределение по категориям')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы видим явную несбалансированность классов для обеих переменных. Скорее всего, при использовании подобного датасета наша простая модель будет склоняться к предсказанию чаще встречающихся классов, то есть будет предвзята (biased).\n"
      ],
      "metadata": {
        "id": "qQATKYD2X9q2"
      },
      "id": "qQATKYD2X9q2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2* (Удаление классов)\n",
        "Если у вас в варианте указана дополнительная работа над целевой переменной, удалите из таблицы соответствующие строки."
      ],
      "metadata": {
        "id": "1AJKBg0rjRDo"
      },
      "id": "1AJKBg0rjRDo"
    },
    {
      "cell_type": "code",
      "source": [
        "#### ВСТАВЬТЕ КОД СЮДА\n",
        "...\n",
        "####"
      ],
      "metadata": {
        "id": "sreWgDeFjQPI"
      },
      "id": "sreWgDeFjQPI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Таблца теперь содержит {df_text.shape[0]} строк.')"
      ],
      "metadata": {
        "id": "BGMgH5_hlCdZ"
      },
      "id": "BGMgH5_hlCdZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6ff14648",
      "metadata": {
        "id": "6ff14648"
      },
      "source": [
        "# Предварительная обработка текстовых данных"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 3 (Предварительная обработка)\n",
        "\n",
        "\n",
        "*   Удалите из текстов обращений лишние символы, оставьте только слова (буквы)\n",
        "*   Приведите слова к нижнеу регистру\n",
        "*   Удалите русские стоп-слова из списка nltk.corpus.stopwords.words(\"russian\")\n",
        "*   Проведите нормализацию слов. В зависимости от варианта, стемминг (используйте nltk.stem.snowball.SnowballStemmer()) или лемматизацию (используйте pymorphy3.MorphAnalyzer())\n"
      ],
      "metadata": {
        "id": "OFCZhkToc-8x"
      },
      "id": "OFCZhkToc-8x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7c65378-fca9-4875-8fb2-f42e303df86c",
      "metadata": {
        "id": "a7c65378-fca9-4875-8fb2-f42e303df86c"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Можете использовать шаблон ниже, он поможет наглядно сравнить значения до обработки и после\n",
        "# def preprocess(text):\n",
        "#     ...\n",
        "#     words = text.split()\n",
        "#     tokens = [word for word in ... if ...]\n",
        "#     ...\n",
        "#     return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0729d35-6d17-4a95-a6cb-e94f63bbda6c",
      "metadata": {
        "id": "b0729d35-6d17-4a95-a6cb-e94f63bbda6c"
      },
      "outputs": [],
      "source": [
        "# df_text['clean_text'] = df_text['process_texts'].apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c444eb-a536-4bb1-92b8-2a33551e662a",
      "metadata": {
        "id": "f6c444eb-a536-4bb1-92b8-2a33551e662a"
      },
      "outputs": [],
      "source": [
        "df_text.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вы можете посмотреть на распределение длин обращений в словах, используя код ниже."
      ],
      "metadata": {
        "id": "4xwiwFR0kSP7"
      },
      "id": "4xwiwFR0kSP7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb23d9ed",
      "metadata": {
        "id": "eb23d9ed"
      },
      "outputs": [],
      "source": [
        "# Длина сообщений\n",
        "df_text['len'] = df_text['clean_text'].apply(lambda x: len(x.split()))\n",
        "sns.histplot(df_text['len'], bins=30)\n",
        "plt.title('Распределение длин сообщений (в словах)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd6a85bc",
      "metadata": {
        "id": "bd6a85bc"
      },
      "source": [
        "# Формирование векторов/массивов признаков (feature vectors) для обучения модели"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 4 (Токенизация и векторизация текстов)\n",
        "\n",
        "Используйте методы fit_on_texts() и texts_to_matrix() класса Tokenizer для формирования словаря и векторизации текстов с учётом вашего варианта! (num_words и mode в texts_to_matrix())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h56l2-E0lxvW"
      },
      "id": "h56l2-E0lxvW"
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df_text['clean_text'].values #Извлекаем все тексты обращений"
      ],
      "metadata": {
        "id": "FoL4jufrlsRO"
      },
      "id": "FoL4jufrlsRO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### ВСТАВЬТЕ КОД СЮДА\n",
        "# ...\n",
        "# xAll =\n",
        "####\n",
        "print(xAll.shape)  # Посмотрим на размерность матрицы\n",
        "print(xAll[0, :20])# И отдельно на фрагмент начала первого вектора"
      ],
      "metadata": {
        "id": "cfA7nZOonBvj"
      },
      "id": "cfA7nZOonBvj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 5 (Кодирование категориальных целевых перемменных - Labelling)"
      ],
      "metadata": {
        "id": "oJZw5C3PnCxU"
      },
      "id": "oJZw5C3PnCxU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вставьте пропущенные строки кода (по вариантам)"
      ],
      "metadata": {
        "id": "pwE-vl0hopMa"
      },
      "id": "pwE-vl0hopMa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b6c1d7d-6d10-424f-86d2-f661c3ea11d5",
      "metadata": {
        "id": "6b6c1d7d-6d10-424f-86d2-f661c3ea11d5"
      },
      "outputs": [],
      "source": [
        "#### ВСТАВЬТЕ КОД СЮДА\n",
        "# ...\n",
        "# classes =\n",
        "# nClasses =\n",
        "####\n",
        "\n",
        "#Преобразовываем категории в вектор целевой переменной\n",
        "encoder = LabelEncoder() # Вызываем метод кодирования категориальных переменных из библиотеки sklearn\n",
        "encoder.fit(classes) # Подгружаем в него категории\n",
        "classesEncoded = encoder.transform(classes) # Кодируем категории\n",
        "print(\"Все классы: \", encoder.classes_)\n",
        "print(\"Длина вектора: \", classesEncoded.shape)\n",
        "print(\"Начало вектора: \",classesEncoded[:20])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yAll = utils.to_categorical(classesEncoded, nClasses) # И выводим каждый лейбл в виде вектора длиной 22,\n",
        "# с 1кой в позиции соответствующего класса и нулями (one-hot encoding)\n",
        "print(\"Форма полученной матрицы: \", yAll.shape)\n",
        "print(\"Отдельная вектор-строка матрицы, указывающая на класс \" + encoder.classes_[classesEncoded[0]] + \": \", yAll[0]) # И отдельный вектор - строку матрицы, указывающую на класс 'Дороги и транспорт'"
      ],
      "metadata": {
        "id": "EXROURr7pLGk"
      },
      "id": "EXROURr7pLGk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 6 (Разбиение н тренировочную и тестовую выборки)\n",
        "Используйте метод train_test_split(), проверьте, есть ли дополнительные требования в варианте"
      ],
      "metadata": {
        "id": "QPhwM7rIpmM7"
      },
      "id": "QPhwM7rIpmM7"
    },
    {
      "cell_type": "code",
      "source": [
        "#### ВСТАВЬТЕ КОД СЮДА\n",
        "# ...\n",
        "# xTrain, xVal, yTrain, yVal =\n",
        "####"
      ],
      "metadata": {
        "id": "cXAFKAfop_tg"
      },
      "id": "cXAFKAfop_tg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a98a710f",
      "metadata": {
        "id": "a98a710f"
      },
      "source": [
        "## Построение простейшей нейронной сети для классификации в Tensorflow.Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebe4b638",
      "metadata": {
        "id": "ebe4b638"
      },
      "outputs": [],
      "source": [
        "#Создаём полносвязную сеть\n",
        "model01 = Sequential()\n",
        "#Входной полносвязный слой\n",
        "model01.add(Dense(100, input_dim=maxWordsCount,\n",
        "                  activation=\"relu\"))\n",
        "#Слой регуляризации Dropout\n",
        "model01.add(Dropout(0.4))\n",
        "#Второй полносвязный слой\n",
        "model01.add(Dense(100, activation='relu'))\n",
        "#Слой регуляризации Dropout\n",
        "model01.add(Dropout(0.4))\n",
        "#Третий полносвязный слой\n",
        "model01.add(Dense(100, activation='relu'))\n",
        "#Слой регуляризации Dropout\n",
        "model01.add(Dropout(0.4))\n",
        "#Выходной полносвязный слой\n",
        "model01.add(Dense(nClasses, activation='softmax'))\n",
        "\n",
        "\n",
        "model01.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Обучаем сеть на выборке\n",
        "history = model01.fit(xTrain,\n",
        "                    yTrain,\n",
        "                    epochs=20,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(xVal, yVal))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка качества обучения  "
      ],
      "metadata": {
        "id": "hP48p318qVuU"
      },
      "id": "hP48p318qVuU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f44e3bb6-dad3-458d-a2b5-58fedd477dfb",
      "metadata": {
        "id": "f44e3bb6-dad3-458d-a2b5-58fedd477dfb"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'],\n",
        "         label='Доля верных ответов на обучающем наборе')\n",
        "plt.plot(history.history['val_accuracy'],\n",
        "         label='Доля верных ответов на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Доля верных ответов')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "plt.plot(history.history['loss'],\n",
        "         label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'],\n",
        "         label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Ошибка')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "toCO6y1_qaf3"
      },
      "id": "toCO6y1_qaf3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model01.summary()"
      ],
      "metadata": {
        "id": "VDoN_IRNqe-B"
      },
      "id": "VDoN_IRNqe-B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8f040fbf",
      "metadata": {
        "id": "8f040fbf"
      },
      "source": [
        "# Формирование прогноза (Inference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd22f776-8256-412f-9ebe-2dc4cd0c43ec",
      "metadata": {
        "id": "cd22f776-8256-412f-9ebe-2dc4cd0c43ec"
      },
      "outputs": [],
      "source": [
        "currPred = model01.predict(xTrain[[11]])\n",
        "#Определяем номер распознанного класса для каждохо блока слов\n",
        "currOut = np.argmax(currPred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e10aeb63-94c4-4918-9e70-6e4c14b926d7",
      "metadata": {
        "id": "e10aeb63-94c4-4918-9e70-6e4c14b926d7"
      },
      "outputs": [],
      "source": [
        "currOut"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.inverse_transform(currOut)"
      ],
      "metadata": {
        "id": "wFi6jNPYq6tn"
      },
      "id": "wFi6jNPYq6tn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = np.argmax(yTrain[11], axis=0)\n",
        "\n",
        "label"
      ],
      "metadata": {
        "id": "qZL1uDDPq-Yx"
      },
      "id": "qZL1uDDPq-Yx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yTrain[11]"
      ],
      "metadata": {
        "id": "4ayfOeqfrEv5"
      },
      "id": "4ayfOeqfrEv5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.inverse_transform([label])"
      ],
      "metadata": {
        "id": "8aSMoT9HrHko"
      },
      "id": "8aSMoT9HrHko",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = pd.DataFrame([xTrain[11]]) #берем матричный вид обращения\n",
        "df_1.columns = list_columns\n",
        "df_1[df_1>0].dropna(axis = 1).columns"
      ],
      "metadata": {
        "id": "3rg9H8oJrMoz"
      },
      "id": "3rg9H8oJrMoz",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}